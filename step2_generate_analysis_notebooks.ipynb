{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6dc956-7cec-4fa3-85fa-58bbf44046ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Generate and run per-model analysis notebooks\n",
    "\n",
    "Depends on: downloaded batch results files from OpenAI Batch API downloaded to `/output_data/umg_{employee|employer}_v2_{model_version}_batch_{hash}.jsonl`\n",
    "\n",
    "This notebook can only be run after the JSONL prompt files generated in step 1 are submitted to the OpenAI Batch API and then JSONL results are downloaded to `/output_data/`,  which we did manually using the web-based interface. Each of the 8 JSONL result files contain all results for either an employee or an employer prompt tested on a model version.\n",
    "\n",
    "This notebook programmatically creates and runs 8 notebooks, one for each result file. The template notebook is `step2_model_x_runtype_notebooks/umg_analysis_template.ipynb`, and this notebook inserts metadata for each permutation of prompt type and model version. Each of the 8 notebooks parses the JSONL to a long-format CSV, one row per prompt, with all the metadata for each prompt (model run, employee vs employer, major, university, pronoun, uni ranking, uni region, etc.) in columns. Each notebook also generates results in `results`. \n",
    "\n",
    "Outputs, for each of 8 files in `/output_data/`:\n",
    "- 1 IPYNB file for each result file: `/step2_model_x_runtype_notebooks/umg_{employee|employer}_analysis_{model_version}.ipynb`\n",
    "- 1 CSV file of median offer by university and major: `/results/umg_{employee|employer}_{model_version}_median_by_uni_major.csv`\n",
    "- 1 CSV file of all parsed results with metadata: `/parsed_data/umg_parsed_queries_v2_{employee|employer}_{model_version}.csv`\n",
    "- 1 PDF and 1 PNG heatmaps of median response by university and major: `/results/university_major_{model_version}_median_response_uni_major_table.{pdf|png}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e3127f-a522-41b7-a257-39115395e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbformat import NotebookNode\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c83b7c7-8db8-4a60-af5e-736ff8fec93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec09baa-6620-41b4-811f-bc2e561ad04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_notebook(template_path, new_path, run_type, gpt_fn, header):\n",
    "    # Load the Jupyter notebook\n",
    "    with open(template_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Prepare the new content for cell 1\n",
    "    new_content = f\"\"\"run_type='{run_type}'\n",
    "gpt_name = '{header}'\n",
    "gpt_fn = '{gpt_fn}'\"\"\"\n",
    "\n",
    "    # Check if the notebook has at least 2 cells and the second cell is a code cell\n",
    "    if len(nb.cells) > 1 and nb.cells[1].cell_type == 'code':\n",
    "        nb.cells[1].source = new_content\n",
    "    else:\n",
    "        print(\"Error: The template does not have a second cell as a code cell.\")\n",
    "        return\n",
    "    \n",
    "    nb.cells[0].source = f\"# {header}\"\n",
    "\n",
    "    # Save the modified notebook\n",
    "    with open(new_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf23f6a7-05b6-4ab6-abbd-4c1ba3a6ba27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_header(run_type, gpt_fn):\n",
    "    header = f\"{run_type.capitalize()} Salary Advice from GPT \"\n",
    "    \n",
    "    if gpt_fn == 'gpt-4o-2024-05-13':\n",
    "        header += \"4o (trained May 2024)\"\n",
    "    elif gpt_fn == 'gpt-4-turbo-2024-04-09':\n",
    "        header += \"4 Turbo (trained April 2024)\"\n",
    "    elif gpt_fn == 'gpt-3.5-turbo-0125':\n",
    "        header += \"3.5 Turbo (trained Jan 2024)\"\n",
    "    elif gpt_fn == 'gpt-3.5-turbo-0613':\n",
    "        header += \"3.5 Turbo (trained Jun 2023)\"\n",
    "    else:\n",
    "        raise Exception(f\"Bad gpt_fn: {gpt_fn}\")\n",
    "\n",
    "    return header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b6e350-905c-423f-946a-54754fddc53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "\n",
    "def execute_notebook(path):\n",
    "    # Load the notebook\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Configure the notebook execution preprocessor\n",
    "    ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "\n",
    "    # Execute the notebook\n",
    "    try:\n",
    "        ep.preprocess(nb, {'metadata': {'path': './step2_model_x_runtype_notebooks'}})\n",
    "    except CellExecutionError as e:\n",
    "        print(f\"Error executing the notebook '{path}'.\\nSee notebook for the error.\")\n",
    "        raise e\n",
    "    except TimeoutError as e:\n",
    "        print(f\"Execution of the notebook '{path}' timed out.\")\n",
    "        raise e\n",
    "\n",
    "    # Save the notebook with the outputs\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13524e8-c2e4-4b94-887b-a74d6c10fcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "template_path = './step2_model_x_runtype_notebooks/umg_step2_analysis_template.ipynb'\n",
    "output_folder = './step2_model_x_runtype_notebooks'\n",
    "run_types = ['employee', 'employer']\n",
    "gpt_fns = ['gpt-3.5-turbo-0613', 'gpt-4o-2024-05-13', 'gpt-4-turbo-2024-04-09', 'gpt-3.5-turbo-0125']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1e3350-a27c-4744-88c5-05d6f3baea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Salary Advice from GPT 3.5 Turbo (trained Jun 2023) ./step2_model_x_runtype_notebooks/umg_employee_analysis_gpt-3.5-turbo-0613.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:20<02:21, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Salary Advice from GPT 4o (trained May 2024) ./step2_model_x_runtype_notebooks/umg_employee_analysis_gpt-4o-2024-05-13.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:40<02:00, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Salary Advice from GPT 4 Turbo (trained April 2024) ./step2_model_x_runtype_notebooks/umg_employee_analysis_gpt-4-turbo-2024-04-09.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:59<01:39, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Salary Advice from GPT 3.5 Turbo (trained Jan 2024) ./step2_model_x_runtype_notebooks/umg_employee_analysis_gpt-3.5-turbo-0125.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [01:19<01:19, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employer Salary Advice from GPT 3.5 Turbo (trained Jun 2023) ./step2_model_x_runtype_notebooks/umg_employer_analysis_gpt-3.5-turbo-0613.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [01:38<00:59, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employer Salary Advice from GPT 4o (trained May 2024) ./step2_model_x_runtype_notebooks/umg_employer_analysis_gpt-4o-2024-05-13.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [01:58<00:39, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employer Salary Advice from GPT 4 Turbo (trained April 2024) ./step2_model_x_runtype_notebooks/umg_employer_analysis_gpt-4-turbo-2024-04-09.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [02:18<00:19, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employer Salary Advice from GPT 3.5 Turbo (trained Jan 2024) ./step2_model_x_runtype_notebooks/umg_employer_analysis_gpt-3.5-turbo-0125.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:38<00:00, 19.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop over each combination of run_type and gpt_fn\n",
    "with tqdm(total = len(run_types) * len(gpt_fns)) as pbar:\n",
    "    for run_type in run_types:\n",
    "        for gpt_fn in gpt_fns:\n",
    "            header = generate_header(run_type, gpt_fn)\n",
    "            new_fn = f\"{output_folder}/umg_{run_type}_analysis_{gpt_fn}.ipynb\"\n",
    "            print(header, new_fn)\n",
    "            update_notebook(template_path, new_fn, run_type, gpt_fn, header)\n",
    "            execute_notebook(new_fn)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb59cc83-2959-4343-9f36-f87987f600d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:02:38.372026\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "print(\"Elapsed time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbcea5-769a-450d-87a7-e06822acc3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
